{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab489e29-cb3d-40e7-8841-b1baed29baf9",
   "metadata": {},
   "source": [
    "# 7 Input/Output in vanilla python, numpy and pandas\n",
    "\n",
    "In this notebook we'll cover reading and writing files using the built-in functionality, and two third party packages that you need to have installed. This course doesn't really cover `pandas`, but since the file-reading functionality is quite convenient, I'll show you the application briefly. In this notebook we'll start with the project as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25509720-422e-4471-a610-6dd07fb64d55",
   "metadata": {},
   "source": [
    "## 7.1 Reading and writing files with open()\n",
    "\n",
    "If you read or wrote into a language-agnostic file before (e.g. while logging your experiment), you've probably seen or written something like this in MATLAB:\n",
    "\n",
    "```\n",
    "f = fopen(\"sub1.log\", \"w\");\n",
    "fprintf(f, \"reaction took %f seconds\\n\", rt);\n",
    "fclose(f);\n",
    "```\n",
    "\n",
    "What you're doing here is opening up the file with the specified permission. In the case above, we opened the file with writing permission (`\"w\"`). You can also use read permission (`\"r\"`), append permission (`\"a\"`, which unline `w` doesn't overwrite the previous content) and multiple at once (e.g. `\"w+\"` or `\"r+\"` to both read and write). Closing the file is important to prevent corrupted files (i.e. something unexpected happens to the content).\n",
    "\n",
    "If you were to translate the part above directly into Python, it would look like this:\n",
    "\n",
    "```python\n",
    "f = open(\"sub1.log\", \"w\")\n",
    "f.write(f\"reaction took {rt} seconds\\n\")\n",
    "f.close()\n",
    "```\n",
    "\n",
    "So you see the principle is the same, but notice the differences:\n",
    " * `open` instead of `fopen`\n",
    " * `.write` and `.close` are methods of the object which represents the stream into the file.\n",
    " \n",
    "One nifty trick to prevent having to close the file again is to use a `context manager`. Those are more fit for a late intermediate course than a beginner's course, but the bottom line in the context of opening a file is, that it gets closed for you once you leave the code block:\n",
    "\n",
    "```python\n",
    "with open(\"sub1.log\", \"w\") as f:\n",
    "    f.write(f\"reaction took {rt} seconds\\n\")\n",
    "```\n",
    "\n",
    "Depending on the permission, the text stream object provides you with a few functions to read from or write to the file:\n",
    "\n",
    " * in read mode\n",
    "    * `.read()`\n",
    "    * `.readlines()`\n",
    " * in write mode\n",
    "    * `.write()`\n",
    "    * `.writelines()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea13c96-db44-44c3-afd9-63dfbd7a3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    l = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febdc58-94ca-46f4-b1bb-6b96831a6060",
   "metadata": {},
   "source": [
    "In the data folder, there's a .csv file that we'll use to get to know the scientific python stack.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Open the file with reading permission and read the content both using `.read` and `readlines`. You'll have to open the file twice, because if you ran either one of these methods, the file has already been read \"until the end\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f3ebd-e4b9-4bd6-9929-e795a833f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434737e-a0e4-4238-b3a2-2cf742b617a9",
   "metadata": {},
   "source": [
    "## 7.2 Using numpy\n",
    "\n",
    "With `open` we can read any content in a file as a string. For numeric data, you'll have to process the string in order to do any analysis. Numpy offers solutions to this. We're going to assume that the data is present in a human-readable way. There are also ways to store numpy arrays in another form, but we won't cover that.\n",
    "\n",
    "The function we'll use to read the data using numpy is `.genfromtxt`. It takes a bunch of potential arguments that make it very flexible, but also complicated. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fae6a-db82-44fc-aa99-528516951249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.genfromtxt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285f6ec-c207-4a0f-89ad-a8ee7c9f2d6b",
   "metadata": {},
   "source": [
    "To direct your attention towards some important ones: `delimiter` specifies the character between values in the file (e.g. \",\" or \"\\t\"). `skipheader` specifices whether the first line should be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88d3aa-b0f2-41b7-be3c-9d1aa4c2501c",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Read the same file as above, but using `numpy` this time. Make sure that you specify the right arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57d173-df3a-46e1-a5ac-d91c97928d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f55d2b-9a00-4c3a-b1e0-dd2fb18a9683",
   "metadata": {},
   "source": [
    "## 7.3 Using pandas \n",
    "\n",
    "I said before that we con't cover `pandas` here, which is almost true. The one exception I'm making is the file-reading part, because it shows you what a DataFrame looks like. For the kind of data we're handling here, a DataFrame would probably be the way to go, but I'll stick to the design principles of the workshop and just show you what `pandas` would look like if you want to use it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7f9eb-6666-41b3-9160-618b84cd00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = \"../data/data.csv\"\n",
    "df = pd.read_csv(filename, delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32e752-1024-42c1-a1d6-7175fb48b5e5",
   "metadata": {},
   "source": [
    "## 7.4 The pickle module\n",
    "\n",
    "Unlike the options you saw so far, `pickle` gives you a way to store most python objects in a python-specific way. If you have a complicated object that can't be stored in a human-readable file, `pickle` is the way to go. There are really only two functions you need to know:\n",
    "\n",
    " * `pickle.load`\n",
    " * `pickle.dump`\n",
    "\n",
    "Because pickling means translating into a stream of 0s and 1s, we need to open files in binary mode. Assuming we have some complex python object that we want to save:\n",
    "\n",
    "```python\n",
    "with open(\"outfile.pic\", \"wb\") as f: #notice I added the b for binary\n",
    "    pickle.dump(complex_object, f, -1)\n",
    "```\n",
    "\n",
    "We added a \"b\" to get _binary_ writing permission. The `-1` refers to the protocol that is used to serialize the data and refers to the highest available protocol. You can ommit it as well.\n",
    "\n",
    "If we want to read the object back in, we can to it like this:\n",
    "\n",
    "```python\n",
    "with open(\"outfile.pic\", \"rb\") as f:\n",
    "    complex_object = pickle.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40142430-9bc4-4d9a-866a-ac5d4bb4109f",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "There's a mysterious string in the data folder. Try to load it using `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a3736-9efc-493d-b6ec-8dbaddd4bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ae2ab-c6fe-496e-848d-1c75af90efba",
   "metadata": {},
   "source": [
    "## 7.5 Reading proprietary files\n",
    "\n",
    "Assuming your collaborators send you a `.mat` or `.sav` file, there are ways to read these as well. For `.mat` files you can use `scipy.io.loadmat` (which is a pain in the ass if you have deeply nested MATLAB structures). For SPSS `.sav` files, you can use `pyreadstat.read_sav` or `pandas.read_spss` which relies on `pyreadstats`. The data we're using was originally a `.sav` file, so this is what I used to read the file, extract the relevant columns and write a `.tsv`-file. `.tsv` are language-agnostic and have values separated by tabs. They're used in the BIDS-format and can be read with any programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d51ea-6286-4706-9beb-ada727a91082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sav_file = '../data/data.sav'\n",
    "df = pd.read_spss(sav_file) # read the file\n",
    "df = df[['Grip', 'Sex', 'Anxiety']] # select relevant columns\n",
    "df.Sex.replace({'Male': 0, 'Female': 1}, inplace=True) # make Sex a numeric variable\n",
    "df.to_csv(sav_file.replace('.sav', '.tsv'), sep='\\t', index=False) # write tsv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a34dd-99f9-4549-908a-68b18799ae06",
   "metadata": {},
   "source": [
    "## 7.6 Starting your project\n",
    "\n",
    "It's finally time to start the mini-project that we're developing concurrently. Head over to the notebook `B01_project_exercises.ipynb` for your first assignment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
